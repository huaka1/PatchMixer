Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=1024, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=256, data='ETTh2', data_path='ETTh2.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1', distil=True, do_predict=False, dropout=0.2, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=0, learning_rate=0.0001, loss='mse', loss_flag=2, lradj='type3', mixer_kernel_size=8, model='PatchMixer', model_id='336_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=10, pct_start=0.3, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/ETT-small/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : loss_flag2_lr0.0001_dm256_336_96_PatchMixer_ETTh2_ftM_sl336_pl96_p16s8_random2021_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
Epoch: 1 cost time: 2.0849428176879883
Epoch: 1, Steps: 8 | Train Loss: 0.5491711 Vali Loss: 0.3742942 Test Loss: 0.3330289
Validation loss decreased (inf --> 0.374294).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.03133487701416
Epoch: 2, Steps: 8 | Train Loss: 0.4827646 Vali Loss: 0.3132795 Test Loss: 0.3134671
Validation loss decreased (0.374294 --> 0.313280).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.0769054889678955
Epoch: 3, Steps: 8 | Train Loss: 0.4581041 Vali Loss: 0.3003896 Test Loss: 0.2945841
Validation loss decreased (0.313280 --> 0.300390).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.1308469772338867
Epoch: 4, Steps: 8 | Train Loss: 0.4186021 Vali Loss: 0.2802789 Test Loss: 0.2775006
Validation loss decreased (0.300390 --> 0.280279).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.0741868019104004
Epoch: 5, Steps: 8 | Train Loss: 0.3981170 Vali Loss: 0.2689697 Test Loss: 0.2735558
Validation loss decreased (0.280279 --> 0.268970).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.090364933013916
Epoch: 6, Steps: 8 | Train Loss: 0.3907414 Vali Loss: 0.2670909 Test Loss: 0.2689605
Validation loss decreased (0.268970 --> 0.267091).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.1248130798339844
Epoch: 7, Steps: 8 | Train Loss: 0.3831049 Vali Loss: 0.2681072 Test Loss: 0.2642880
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.0948565006256104
Epoch: 8, Steps: 8 | Train Loss: 0.3764105 Vali Loss: 0.2635689 Test Loss: 0.2639785
Validation loss decreased (0.267091 --> 0.263569).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.051501989364624
Epoch: 9, Steps: 8 | Train Loss: 0.3729776 Vali Loss: 0.2621451 Test Loss: 0.2645762
Validation loss decreased (0.263569 --> 0.262145).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.098524808883667
Epoch: 10, Steps: 8 | Train Loss: 0.3697838 Vali Loss: 0.2602327 Test Loss: 0.2637474
Validation loss decreased (0.262145 --> 0.260233).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.0468597412109375
Epoch: 11, Steps: 8 | Train Loss: 0.3667996 Vali Loss: 0.2641650 Test Loss: 0.2629696
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.1228647232055664
Epoch: 12, Steps: 8 | Train Loss: 0.3645708 Vali Loss: 0.2597319 Test Loss: 0.2627459
Validation loss decreased (0.260233 --> 0.259732).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.0612592697143555
Epoch: 13, Steps: 8 | Train Loss: 0.3628043 Vali Loss: 0.2608119 Test Loss: 0.2626250
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.0693769454956055
Epoch: 14, Steps: 8 | Train Loss: 0.3610761 Vali Loss: 0.2596957 Test Loss: 0.2626869
Validation loss decreased (0.259732 --> 0.259696).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.106776237487793
Epoch: 15, Steps: 8 | Train Loss: 0.3596926 Vali Loss: 0.2603490 Test Loss: 0.2627369
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.100696086883545
Epoch: 16, Steps: 8 | Train Loss: 0.3586507 Vali Loss: 0.2607642 Test Loss: 0.2629334
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.156352996826172
Epoch: 17, Steps: 8 | Train Loss: 0.3573054 Vali Loss: 0.2615291 Test Loss: 0.2629896
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.1057417392730713
Epoch: 18, Steps: 8 | Train Loss: 0.3565330 Vali Loss: 0.2587529 Test Loss: 0.2631781
Validation loss decreased (0.259696 --> 0.258753).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.0655713081359863
Epoch: 19, Steps: 8 | Train Loss: 0.3553634 Vali Loss: 0.2584190 Test Loss: 0.2632864
Validation loss decreased (0.258753 --> 0.258419).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.11604905128479
Epoch: 20, Steps: 8 | Train Loss: 0.3549137 Vali Loss: 0.2610459 Test Loss: 0.2632960
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.070284128189087
Epoch: 21, Steps: 8 | Train Loss: 0.3534579 Vali Loss: 0.2599725 Test Loss: 0.2633328
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.1139369010925293
Epoch: 22, Steps: 8 | Train Loss: 0.3530979 Vali Loss: 0.2583831 Test Loss: 0.2633831
Validation loss decreased (0.258419 --> 0.258383).  Saving model ...
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.074305534362793
Epoch: 23, Steps: 8 | Train Loss: 0.3528876 Vali Loss: 0.2605531 Test Loss: 0.2634565
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.1110851764678955
Epoch: 24, Steps: 8 | Train Loss: 0.3520090 Vali Loss: 0.2604894 Test Loss: 0.2635183
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.1296544075012207
Epoch: 25, Steps: 8 | Train Loss: 0.3516471 Vali Loss: 0.2614505 Test Loss: 0.2635410
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.1096553802490234
Epoch: 26, Steps: 8 | Train Loss: 0.3513828 Vali Loss: 0.2605093 Test Loss: 0.2636316
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.0633163452148438
Epoch: 27, Steps: 8 | Train Loss: 0.3507685 Vali Loss: 0.2604643 Test Loss: 0.2636621
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.0423824787139893
Epoch: 28, Steps: 8 | Train Loss: 0.3505031 Vali Loss: 0.2606713 Test Loss: 0.2637295
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.123427391052246
Epoch: 29, Steps: 8 | Train Loss: 0.3499403 Vali Loss: 0.2595164 Test Loss: 0.2637410
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.0866990089416504
Epoch: 30, Steps: 8 | Train Loss: 0.3500108 Vali Loss: 0.2580416 Test Loss: 0.2637532
Validation loss decreased (0.258383 --> 0.258042).  Saving model ...
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.1027629375457764
Epoch: 31, Steps: 8 | Train Loss: 0.3493427 Vali Loss: 0.2604981 Test Loss: 0.2637846
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.009436845779419
Epoch: 32, Steps: 8 | Train Loss: 0.3492196 Vali Loss: 0.2615004 Test Loss: 0.2638511
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.061068058013916
Epoch: 33, Steps: 8 | Train Loss: 0.3492002 Vali Loss: 0.2596771 Test Loss: 0.2638638
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.053647041320801
Epoch: 34, Steps: 8 | Train Loss: 0.3485137 Vali Loss: 0.2603917 Test Loss: 0.2638718
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.042013168334961
Epoch: 35, Steps: 8 | Train Loss: 0.3485376 Vali Loss: 0.2589395 Test Loss: 0.2639491
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.0879464149475098
Epoch: 36, Steps: 8 | Train Loss: 0.3483909 Vali Loss: 0.2592794 Test Loss: 0.2639553
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.0416815280914307
Epoch: 37, Steps: 8 | Train Loss: 0.3486060 Vali Loss: 0.2586377 Test Loss: 0.2640011
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7812838944369375e-06
Epoch: 38 cost time: 2.098207712173462
Epoch: 38, Steps: 8 | Train Loss: 0.3486839 Vali Loss: 0.2629598 Test Loss: 0.2639915
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.503155504993244e-06
Epoch: 39 cost time: 2.09550404548645
Epoch: 39, Steps: 8 | Train Loss: 0.3485019 Vali Loss: 0.2598180 Test Loss: 0.2639534
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.2528399544939195e-06
Epoch: 40 cost time: 2.103477954864502
Epoch: 40, Steps: 8 | Train Loss: 0.3478120 Vali Loss: 0.2605014 Test Loss: 0.2639647
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : loss_flag2_lr0.0001_dm256_336_96_PatchMixer_ETTh2_ftM_sl336_pl96_p16s8_random2021_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.22650280594825745, mae:0.3010037839412689, rse:0.39208322763442993
