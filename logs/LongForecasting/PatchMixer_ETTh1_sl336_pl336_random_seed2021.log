Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=1024, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=256, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1', distil=True, do_predict=False, dropout=0.2, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=0, learning_rate=0.0001, loss='mse', loss_flag=2, lradj='type3', mixer_kernel_size=8, model='PatchMixer', model_id='336_336', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=10, pct_start=0.3, pred_len=336, random_seed=2021, revin=1, root_path='./dataset/ETT-small/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : loss_flag2_lr0.0001_dm256_336_336_PatchMixer_ETTh1_ftM_sl336_pl336_p16s8_random2021_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
Epoch: 1 cost time: 1.9662115573883057
vali loss: 1.6519252061843872
vali loss: 0.6959717273712158
Epoch: 1, Steps: 7 | Train Loss: 0.6722915 Vali Loss: 1.2900894 Test Loss: 0.6361948
Validation loss decreased (inf --> 1.290089).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.0601937770843506
vali loss: 1.4629580974578857
vali loss: 0.5971727967262268
Epoch: 2, Steps: 7 | Train Loss: 0.5885929 Vali Loss: 1.1567240 Test Loss: 0.5639045
Validation loss decreased (1.290089 --> 1.156724).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.246520757675171
vali loss: 1.3752541542053223
vali loss: 0.5087746977806091
Epoch: 3, Steps: 7 | Train Loss: 0.5863404 Vali Loss: 1.0929196 Test Loss: 0.4966454
Validation loss decreased (1.156724 --> 1.092920).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.0258116722106934
vali loss: 1.2445513010025024
vali loss: 0.4473707675933838
Epoch: 4, Steps: 7 | Train Loss: 0.5214642 Vali Loss: 1.0101323 Test Loss: 0.4544934
Validation loss decreased (1.092920 --> 1.010132).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.0421504974365234
vali loss: 1.1917845010757446
vali loss: 0.41484180092811584
Epoch: 5, Steps: 7 | Train Loss: 0.5069427 Vali Loss: 0.9756703 Test Loss: 0.4270686
Validation loss decreased (1.010132 --> 0.975670).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.0710527896881104
vali loss: 1.172321081161499
vali loss: 0.4000658690929413
Epoch: 6, Steps: 7 | Train Loss: 0.4945307 Vali Loss: 0.9599663 Test Loss: 0.4123229
Validation loss decreased (0.975670 --> 0.959966).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 1.9788305759429932
vali loss: 1.1857011318206787
vali loss: 0.4072740972042084
Epoch: 7, Steps: 7 | Train Loss: 0.4872749 Vali Loss: 0.9669592 Test Loss: 0.4173324
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.018502950668335
vali loss: 1.2083989381790161
vali loss: 0.40594378113746643
Epoch: 8, Steps: 7 | Train Loss: 0.4829200 Vali Loss: 0.9790992 Test Loss: 0.4156352
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.152876853942871
vali loss: 1.2103170156478882
vali loss: 0.39973172545433044
Epoch: 9, Steps: 7 | Train Loss: 0.4796783 Vali Loss: 0.9786856 Test Loss: 0.4099925
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 1.98893141746521
vali loss: 1.2020010948181152
vali loss: 0.3945249617099762
Epoch: 10, Steps: 7 | Train Loss: 0.4767711 Vali Loss: 0.9721621 Test Loss: 0.4051834
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 1.9658384323120117
vali loss: 1.1994054317474365
vali loss: 0.3915914297103882
Epoch: 11, Steps: 7 | Train Loss: 0.4741371 Vali Loss: 0.9704825 Test Loss: 0.4020050
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.4577133655548096
vali loss: 1.1766421794891357
vali loss: 0.3910500407218933
Epoch: 12, Steps: 7 | Train Loss: 0.4723997 Vali Loss: 0.9558253 Test Loss: 0.4009615
Validation loss decreased (0.959966 --> 0.955825).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.453464984893799
vali loss: 1.1750538349151611
vali loss: 0.3909737169742584
Epoch: 13, Steps: 7 | Train Loss: 0.4714085 Vali Loss: 0.9544121 Test Loss: 0.4006217
Validation loss decreased (0.955825 --> 0.954412).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.4798882007598877
vali loss: 1.1867045164108276
vali loss: 0.39089006185531616
Epoch: 14, Steps: 7 | Train Loss: 0.4706661 Vali Loss: 0.9616557 Test Loss: 0.4006358
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.087491512298584
vali loss: 1.1888140439987183
vali loss: 0.3906797468662262
Epoch: 15, Steps: 7 | Train Loss: 0.4702502 Vali Loss: 0.9627202 Test Loss: 0.4006720
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.476813316345215
vali loss: 1.1952385902404785
vali loss: 0.39004963636398315
Epoch: 16, Steps: 7 | Train Loss: 0.4685882 Vali Loss: 0.9665918 Test Loss: 0.4003165
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.4017727375030518
vali loss: 1.201422095298767
vali loss: 0.3892653286457062
Epoch: 17, Steps: 7 | Train Loss: 0.4683718 Vali Loss: 0.9707439 Test Loss: 0.3996813
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.4229564666748047
vali loss: 1.1934256553649902
vali loss: 0.38875633478164673
Epoch: 18, Steps: 7 | Train Loss: 0.4679774 Vali Loss: 0.9651537 Test Loss: 0.3992002
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.418755054473877
vali loss: 1.2022099494934082
vali loss: 0.38843852281570435
Epoch: 19, Steps: 7 | Train Loss: 0.4666990 Vali Loss: 0.9705927 Test Loss: 0.3988634
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.4733686447143555
vali loss: 1.198525309562683
vali loss: 0.388185977935791
Epoch: 20, Steps: 7 | Train Loss: 0.4660648 Vali Loss: 0.9683969 Test Loss: 0.3985723
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.441680431365967
vali loss: 1.1952319145202637
vali loss: 0.38819822669029236
Epoch: 21, Steps: 7 | Train Loss: 0.4677982 Vali Loss: 0.9657375 Test Loss: 0.3985114
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.481257438659668
vali loss: 1.2030303478240967
vali loss: 0.38811299204826355
Epoch: 22, Steps: 7 | Train Loss: 0.4669953 Vali Loss: 0.9712725 Test Loss: 0.3984053
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.4721624851226807
vali loss: 1.1957718133926392
vali loss: 0.3880743086338043
Epoch: 23, Steps: 7 | Train Loss: 0.4650010 Vali Loss: 0.9662754 Test Loss: 0.3983502
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : loss_flag2_lr0.0001_dm256_336_336_PatchMixer_ETTh1_ftM_sl336_pl336_p16s8_random2021_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.3909737169742584, mae:0.410269558429718, rse:0.6077483296394348
