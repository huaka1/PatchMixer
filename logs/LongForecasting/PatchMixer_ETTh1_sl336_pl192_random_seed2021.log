Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=1024, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=256, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1', distil=True, do_predict=False, dropout=0.2, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=0, learning_rate=0.0001, loss='mse', loss_flag=2, lradj='type3', mixer_kernel_size=8, model='PatchMixer', model_id='336_192', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=10, pct_start=0.3, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/ETT-small/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : loss_flag2_lr0.0001_dm256_336_192_PatchMixer_ETTh1_ftM_sl336_pl192_p16s8_random2021_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
Epoch: 1 cost time: 2.3775715827941895
Epoch: 1, Steps: 7 | Train Loss: 0.6417918 Vali Loss: 1.2086949 Test Loss: 0.6469339
Validation loss decreased (inf --> 1.208695).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.305713653564453
Epoch: 2, Steps: 7 | Train Loss: 0.5428199 Vali Loss: 1.1134288 Test Loss: 0.6410254
Validation loss decreased (1.208695 --> 1.113429).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 2.2804198265075684
Epoch: 3, Steps: 7 | Train Loss: 0.5522385 Vali Loss: 0.9505926 Test Loss: 0.5094724
Validation loss decreased (1.113429 --> 0.950593).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 2.3227713108062744
Epoch: 4, Steps: 7 | Train Loss: 0.4770557 Vali Loss: 0.8415214 Test Loss: 0.4480408
Validation loss decreased (0.950593 --> 0.841521).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 2.322436809539795
Epoch: 5, Steps: 7 | Train Loss: 0.4616914 Vali Loss: 0.8328027 Test Loss: 0.4266888
Validation loss decreased (0.841521 --> 0.832803).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 2.3789615631103516
Epoch: 6, Steps: 7 | Train Loss: 0.4485675 Vali Loss: 0.8138695 Test Loss: 0.4030003
Validation loss decreased (0.832803 --> 0.813869).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.2979605197906494
Epoch: 7, Steps: 7 | Train Loss: 0.4388807 Vali Loss: 0.8131853 Test Loss: 0.4059198
Validation loss decreased (0.813869 --> 0.813185).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 2.312776565551758
Epoch: 8, Steps: 7 | Train Loss: 0.4345366 Vali Loss: 0.8123448 Test Loss: 0.4043837
Validation loss decreased (0.813185 --> 0.812345).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.3385376930236816
Epoch: 9, Steps: 7 | Train Loss: 0.4291346 Vali Loss: 0.8087952 Test Loss: 0.3975210
Validation loss decreased (0.812345 --> 0.808795).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.3678603172302246
Epoch: 10, Steps: 7 | Train Loss: 0.4261147 Vali Loss: 0.7960652 Test Loss: 0.3928495
Validation loss decreased (0.808795 --> 0.796065).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.306091070175171
Epoch: 11, Steps: 7 | Train Loss: 0.4256985 Vali Loss: 0.7934452 Test Loss: 0.3900884
Validation loss decreased (0.796065 --> 0.793445).  Saving model ...
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.3132822513580322
Epoch: 12, Steps: 7 | Train Loss: 0.4235551 Vali Loss: 0.7871058 Test Loss: 0.3883322
Validation loss decreased (0.793445 --> 0.787106).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.300283908843994
Epoch: 13, Steps: 7 | Train Loss: 0.4221554 Vali Loss: 0.7901416 Test Loss: 0.3875425
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.296318292617798
Epoch: 14, Steps: 7 | Train Loss: 0.4218157 Vali Loss: 0.7836901 Test Loss: 0.3873810
Validation loss decreased (0.787106 --> 0.783690).  Saving model ...
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.3050198554992676
Epoch: 15, Steps: 7 | Train Loss: 0.4205899 Vali Loss: 0.7883291 Test Loss: 0.3871789
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.237663984298706
Epoch: 16, Steps: 7 | Train Loss: 0.4193197 Vali Loss: 0.7847898 Test Loss: 0.3867307
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.2534470558166504
Epoch: 17, Steps: 7 | Train Loss: 0.4193460 Vali Loss: 0.7907169 Test Loss: 0.3861534
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.2494800090789795
Epoch: 18, Steps: 7 | Train Loss: 0.4182775 Vali Loss: 0.7865387 Test Loss: 0.3855801
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.289365768432617
Epoch: 19, Steps: 7 | Train Loss: 0.4181545 Vali Loss: 0.7852017 Test Loss: 0.3852253
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.2956252098083496
Epoch: 20, Steps: 7 | Train Loss: 0.4177187 Vali Loss: 0.7974063 Test Loss: 0.3849554
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.3288228511810303
Epoch: 21, Steps: 7 | Train Loss: 0.4188022 Vali Loss: 0.7895141 Test Loss: 0.3848600
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.373969078063965
Epoch: 22, Steps: 7 | Train Loss: 0.4171651 Vali Loss: 0.7865044 Test Loss: 0.3847441
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.3132059574127197
Epoch: 23, Steps: 7 | Train Loss: 0.4164561 Vali Loss: 0.7924180 Test Loss: 0.3846596
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.302288293838501
Epoch: 24, Steps: 7 | Train Loss: 0.4166297 Vali Loss: 0.7821413 Test Loss: 0.3845927
Validation loss decreased (0.783690 --> 0.782141).  Saving model ...
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.330807685852051
Epoch: 25, Steps: 7 | Train Loss: 0.4162548 Vali Loss: 0.7924423 Test Loss: 0.3845285
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.3039870262145996
Epoch: 26, Steps: 7 | Train Loss: 0.4162466 Vali Loss: 0.7932919 Test Loss: 0.3844321
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.2994370460510254
Epoch: 27, Steps: 7 | Train Loss: 0.4174463 Vali Loss: 0.7792931 Test Loss: 0.3842833
Validation loss decreased (0.782141 --> 0.779293).  Saving model ...
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.2736823558807373
Epoch: 28, Steps: 7 | Train Loss: 0.4158660 Vali Loss: 0.7865493 Test Loss: 0.3842082
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.365709066390991
Epoch: 29, Steps: 7 | Train Loss: 0.4161071 Vali Loss: 0.7842607 Test Loss: 0.3841268
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.280977725982666
Epoch: 30, Steps: 7 | Train Loss: 0.4152527 Vali Loss: 0.7884181 Test Loss: 0.3840250
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.8149737003040096e-06
Epoch: 31 cost time: 2.267204999923706
Epoch: 31, Steps: 7 | Train Loss: 0.4163293 Vali Loss: 0.7848176 Test Loss: 0.3839538
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.23347633027361e-06
Epoch: 32 cost time: 2.3067493438720703
Epoch: 32, Steps: 7 | Train Loss: 0.4160187 Vali Loss: 0.7891384 Test Loss: 0.3839433
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.710128697246249e-06
Epoch: 33 cost time: 2.30077862739563
Epoch: 33, Steps: 7 | Train Loss: 0.4153483 Vali Loss: 0.7906964 Test Loss: 0.3839047
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.239115827521624e-06
Epoch: 34 cost time: 2.329392671585083
Epoch: 34, Steps: 7 | Train Loss: 0.4159949 Vali Loss: 0.7797316 Test Loss: 0.3838981
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.815204244769462e-06
Epoch: 35 cost time: 2.275697708129883
Epoch: 35, Steps: 7 | Train Loss: 0.4156405 Vali Loss: 0.7903575 Test Loss: 0.3838516
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.4336838202925152e-06
Epoch: 36 cost time: 2.320004463195801
Epoch: 36, Steps: 7 | Train Loss: 0.4136216 Vali Loss: 0.7842150 Test Loss: 0.3838060
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.090315438263264e-06
Epoch: 37 cost time: 2.2986152172088623
Epoch: 37, Steps: 7 | Train Loss: 0.4145025 Vali Loss: 0.7974417 Test Loss: 0.3837421
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : loss_flag2_lr0.0001_dm256_336_192_PatchMixer_ETTh1_ftM_sl336_pl192_p16s8_random2021_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.3743639588356018, mae:0.39420250058174133, rse:0.5937364101409912
