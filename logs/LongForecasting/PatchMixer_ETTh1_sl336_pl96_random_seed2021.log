Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=1024, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=256, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1', distil=True, do_predict=False, dropout=0.2, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=0, learning_rate=0.0001, loss='mse', loss_flag=2, lradj='type3', mixer_kernel_size=8, model='PatchMixer', model_id='336_96', moving_avg=25, n_heads=8, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=10, pct_start=0.3, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/ETT-small/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : loss_flag2_lr0.0001_dm256_336_96_PatchMixer_ETTh1_ftM_sl336_pl96_p16s8_random2021_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
Epoch: 1 cost time: 3.809330463409424
Epoch: 1, Steps: 8 | Train Loss: 0.5805905 Vali Loss: 1.0132869 Test Loss: 0.5815926
Validation loss decreased (inf --> 1.013287).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 3.740171432495117
Epoch: 2, Steps: 8 | Train Loss: 0.5847160 Vali Loss: 0.8813211 Test Loss: 0.5753671
Validation loss decreased (1.013287 --> 0.881321).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 3.583512544631958
Epoch: 3, Steps: 8 | Train Loss: 0.5200820 Vali Loss: 0.7622799 Test Loss: 0.4929946
Validation loss decreased (0.881321 --> 0.762280).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 3.493206262588501
Epoch: 4, Steps: 8 | Train Loss: 0.4755092 Vali Loss: 0.7216106 Test Loss: 0.4226734
Validation loss decreased (0.762280 --> 0.721611).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 3.3221147060394287
Epoch: 5, Steps: 8 | Train Loss: 0.4415871 Vali Loss: 0.6897839 Test Loss: 0.4180267
Validation loss decreased (0.721611 --> 0.689784).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 3.03889799118042
Epoch: 6, Steps: 8 | Train Loss: 0.4230755 Vali Loss: 0.6650916 Test Loss: 0.3985464
Validation loss decreased (0.689784 --> 0.665092).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 2.9530763626098633
Epoch: 7, Steps: 8 | Train Loss: 0.4077723 Vali Loss: 0.6449749 Test Loss: 0.3868067
Validation loss decreased (0.665092 --> 0.644975).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 3.0194711685180664
Epoch: 8, Steps: 8 | Train Loss: 0.3986501 Vali Loss: 0.6335909 Test Loss: 0.3790948
Validation loss decreased (0.644975 --> 0.633591).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 2.968770980834961
Epoch: 9, Steps: 8 | Train Loss: 0.3938912 Vali Loss: 0.6297820 Test Loss: 0.3765562
Validation loss decreased (0.633591 --> 0.629782).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 2.7087321281433105
Epoch: 10, Steps: 8 | Train Loss: 0.3898935 Vali Loss: 0.6146318 Test Loss: 0.3736001
Validation loss decreased (0.629782 --> 0.614632).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 2.721328020095825
Epoch: 11, Steps: 8 | Train Loss: 0.3865387 Vali Loss: 0.6195118 Test Loss: 0.3705912
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 2.6736769676208496
Epoch: 12, Steps: 8 | Train Loss: 0.3845033 Vali Loss: 0.6139379 Test Loss: 0.3689234
Validation loss decreased (0.614632 --> 0.613938).  Saving model ...
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 2.8916633129119873
Epoch: 13, Steps: 8 | Train Loss: 0.3832263 Vali Loss: 0.6141878 Test Loss: 0.3683580
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 2.815376043319702
Epoch: 14, Steps: 8 | Train Loss: 0.3818594 Vali Loss: 0.6141354 Test Loss: 0.3680766
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 2.79801344871521
Epoch: 15, Steps: 8 | Train Loss: 0.3807678 Vali Loss: 0.6138241 Test Loss: 0.3675956
Validation loss decreased (0.613938 --> 0.613824).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 2.83974289894104
Epoch: 16, Steps: 8 | Train Loss: 0.3801825 Vali Loss: 0.6160002 Test Loss: 0.3672675
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 2.7567760944366455
Epoch: 17, Steps: 8 | Train Loss: 0.3796211 Vali Loss: 0.6073390 Test Loss: 0.3669233
Validation loss decreased (0.613824 --> 0.607339).  Saving model ...
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 2.7995545864105225
Epoch: 18, Steps: 8 | Train Loss: 0.3789028 Vali Loss: 0.6057167 Test Loss: 0.3669540
Validation loss decreased (0.607339 --> 0.605717).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 2.795912504196167
Epoch: 19, Steps: 8 | Train Loss: 0.3782685 Vali Loss: 0.6030418 Test Loss: 0.3666421
Validation loss decreased (0.605717 --> 0.603042).  Saving model ...
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 2.755131959915161
Epoch: 20, Steps: 8 | Train Loss: 0.3780658 Vali Loss: 0.5997514 Test Loss: 0.3662484
Validation loss decreased (0.603042 --> 0.599751).  Saving model ...
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 2.8064255714416504
Epoch: 21, Steps: 8 | Train Loss: 0.3778108 Vali Loss: 0.6077111 Test Loss: 0.3661743
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5009463529699919e-05
Epoch: 22 cost time: 2.900043487548828
Epoch: 22, Steps: 8 | Train Loss: 0.3772599 Vali Loss: 0.6071305 Test Loss: 0.3662422
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.3508517176729929e-05
Epoch: 23 cost time: 2.8080050945281982
Epoch: 23, Steps: 8 | Train Loss: 0.3770626 Vali Loss: 0.6042553 Test Loss: 0.3662636
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.2157665459056936e-05
Epoch: 24 cost time: 2.8697686195373535
Epoch: 24, Steps: 8 | Train Loss: 0.3770405 Vali Loss: 0.6043430 Test Loss: 0.3662308
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.0941898913151242e-05
Epoch: 25 cost time: 2.876481294631958
Epoch: 25, Steps: 8 | Train Loss: 0.3766838 Vali Loss: 0.6100456 Test Loss: 0.3662477
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.847709021836118e-06
Epoch: 26 cost time: 2.8130950927734375
Epoch: 26, Steps: 8 | Train Loss: 0.3760233 Vali Loss: 0.6044212 Test Loss: 0.3662159
EarlyStopping counter: 6 out of 10
Updating learning rate to 8.862938119652508e-06
Epoch: 27 cost time: 2.857287883758545
Epoch: 27, Steps: 8 | Train Loss: 0.3761009 Vali Loss: 0.6121235 Test Loss: 0.3662502
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.976644307687255e-06
Epoch: 28 cost time: 2.7971715927124023
Epoch: 28, Steps: 8 | Train Loss: 0.3762593 Vali Loss: 0.6126090 Test Loss: 0.3661793
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.178979876918531e-06
Epoch: 29 cost time: 2.8994922637939453
Epoch: 29, Steps: 8 | Train Loss: 0.3759606 Vali Loss: 0.6069434 Test Loss: 0.3660225
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.4610818892266776e-06
Epoch: 30 cost time: 2.8108880519866943
Epoch: 30, Steps: 8 | Train Loss: 0.3757432 Vali Loss: 0.6052955 Test Loss: 0.3658858
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : loss_flag2_lr0.0001_dm256_336_96_PatchMixer_ETTh1_ftM_sl336_pl96_p16s8_random2021_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3522890508174896, mae:0.3802076280117035, rse:0.57365483045578
